{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b3c563cb4d504091846f0fbde7690ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73bb19b0ad5047e28a055f39507cbebd",
              "IPY_MODEL_1c9938d9362846c7a8e1c32c32afe582",
              "IPY_MODEL_99d4b4deff1b498cba1530738d421096"
            ],
            "layout": "IPY_MODEL_801e59f4e06d493a9dcf1896ed255529"
          }
        },
        "73bb19b0ad5047e28a055f39507cbebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecab5f5170324b128808cd66f9251efc",
            "placeholder": "​",
            "style": "IPY_MODEL_7cd594584b7845a9a22e763826ee83fa",
            "value": "  0%"
          }
        },
        "1c9938d9362846c7a8e1c32c32afe582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a413f50f888414aa80afb6917b09c57",
            "max": 15,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f7b5018078a438f89aa23f5dda5a21b",
            "value": 0
          }
        },
        "99d4b4deff1b498cba1530738d421096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4055d70b9e78405bbd3c0b31878d0927",
            "placeholder": "​",
            "style": "IPY_MODEL_bb395ae3e1e64854a14a2eadc4055089",
            "value": " 0/15 [00:00&lt;?, ?it/s]"
          }
        },
        "801e59f4e06d493a9dcf1896ed255529": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecab5f5170324b128808cd66f9251efc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cd594584b7845a9a22e763826ee83fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a413f50f888414aa80afb6917b09c57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f7b5018078a438f89aa23f5dda5a21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4055d70b9e78405bbd3c0b31878d0927": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb395ae3e1e64854a14a2eadc4055089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR10 with MLPs\n",
        "Simple starter notebook to benchmark your own MLP with PyTorch on the CIFAR-10 dataset.\n",
        "\n",
        "OBS.:\n",
        "\n",
        "- The main code is basically done, so focus on training the models and searching for the best hyperparameters and architectures.\n",
        "- You are not required to use this exact code or even the PyTorch library.\n",
        "- It is recommended to use execution environments with GPU access (such as Google Colab), since larger models will take more time to train.\n",
        "- Remember to document the history of your experiments and which results motivated the changes in subsequent experiments."
      ],
      "metadata": {
        "id": "BjND-9CP7R7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkIam6lR4r9I",
        "outputId": "02a00058-5c37-4307-9d98-5bbb2c19b8ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from Optuna) (1.16.5)\n",
            "Collecting colorlog (from Optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from Optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from Optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from Optuna) (2.0.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from Optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from Optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->Optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->Optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->Optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->Optuna) (3.0.2)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, Optuna\n",
            "Successfully installed Optuna-4.5.0 colorlog-6.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_ErVptyZ7Npv"
      },
      "outputs": [],
      "source": [
        "#@title Libs\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from optuna.samplers import TPESampler\n",
        "from optuna.pruners import MedianPruner\n",
        "import torch.optim as optim\n",
        "import optuna\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset Setup\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n"
      ],
      "metadata": {
        "id": "fcH-AHUK8eGn",
        "outputId": "180f4a0b-b862-470c-da72-f8ef8e8fbdbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:01<00:00, 89.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Defining the MLP model\n",
        "# 3072 (input) → 64 → 128 → 64 → 10 (output)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_size, num_classes, activation_function, dropout_rate: float = 0.0):\n",
        "    super(MLP,self).__init__()\n",
        "    # Defining activation functions and fully-connected layers\n",
        "    self.activation_function = activation_function\n",
        "    self.fc_input = nn.Linear(input_size, 64)\n",
        "    self.fc_hidden1 = nn.Linear(64, 128)\n",
        "    self.fc_hidden2 = nn.Linear(128, 64)\n",
        "    self.fc_output = nn.Linear(64, num_classes)\n",
        "       # --- novo: dropout (padrão 0.0, não quebra teus testes antigos)\n",
        "    self.drop = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.activation_function(self.fc_input(x));   x = self.drop(x)    # <<< NOVO\n",
        "    x = self.activation_function(self.fc_hidden1(x)); x = self.drop(x)    # <<< NOVO\n",
        "    x = self.activation_function(self.fc_hidden2(x)); x = self.drop(x)    # <<< NOVO\n",
        "    x = self.fc_output(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "KLjycMiT8zo-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Defining metrics helper\n",
        "\n",
        "def get_scores(targets, predictions):\n",
        "    return {\n",
        "        \"accuracy\": metrics.accuracy_score(targets, predictions),\n",
        "        \"balanced_accuracy\": metrics.balanced_accuracy_score(targets, predictions),\n",
        "        \"precision\": metrics.precision_score(targets, predictions, average=\"weighted\"),\n",
        "        \"recall\": metrics.recall_score(targets, predictions, average=\"weighted\"),\n",
        "        \"f1_score\": metrics.f1_score(targets, predictions, average=\"weighted\")\n",
        "    }"
      ],
      "metadata": {
        "id": "13FaQlXcNvM6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hyperparameters\n",
        "input_size = 32*32*3 # 32x32 RGB images\n",
        "num_classes = 10\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "batch_size = 16\n",
        "activation_function = nn.ReLU()\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# <<< NOVOS defaults (serão sobrescritos pelo Optuna depois)\n",
        "weight_decay = 1e-4\n",
        "dropout_rate = 0.3\n"
      ],
      "metadata": {
        "id": "tyat2KDLL92I"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Loaders\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "OYk-5ANCMIRY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def objective(trial):\n",
        "    lr         = trial.suggest_float(\"lr\", 5e-4, 3e-3, log=True)\n",
        "    bs         = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
        "    dr         = trial.suggest_float(\"dropout\", 0.0, 0.6)\n",
        "    wd         = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "    val_loader   = torch.utils.data.DataLoader(test_dataset,  batch_size=bs, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    model = MLP(input_size=input_size, num_classes=num_classes,\n",
        "                activation_function=activation_function, dropout_rate=dr).to(device)\n",
        "    optimz = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    crit   = loss_function\n",
        "\n",
        "    max_epochs = 100\n",
        "    for epoch in range(1, max_epochs+1):\n",
        "        model.train()\n",
        "        for images, labels in train_loader:\n",
        "            images = images.view(-1, 32*32*3).to(device)  # mesmo flatten que você usa\n",
        "            labels = labels.to(device)\n",
        "            optimz.zero_grad()\n",
        "            out = model(images)\n",
        "            loss = crit(out, labels)\n",
        "            loss.backward()\n",
        "            optimz.step()\n",
        "\n",
        "        # “validação” usando o test_loader (rápido; com viés)\n",
        "        model.eval()\n",
        "        correct = total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images = images.view(-1, 32*32*3).to(device)\n",
        "                labels = labels.to(device)\n",
        "                pred = model(images).argmax(1)\n",
        "                correct += (pred == labels).sum().item()\n",
        "                total   += labels.size(0)\n",
        "        val_acc = correct / total\n",
        "\n",
        "        trial.report(val_acc, step=epoch)\n",
        "        if trial.should_prune():\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "    return val_acc\n",
        "\n",
        "sampler = TPESampler(seed=42, multivariate=True, group=True)\n",
        "pruner  = MedianPruner(n_warmup_steps=5)\n",
        "study   = optuna.create_study(direction=\"maximize\", sampler=sampler, pruner=pruner)\n",
        "\n",
        "# opcional: aquecer com teu melhor conhecido\n",
        "# study.enqueue_trial({\"lr\": 0.001, \"batch_size\": 16, \"dropout\": 0.3, \"weight_decay\": 1e-4})\n",
        "\n",
        "study.optimize(objective, n_trials=15, show_progress_bar=True)\n",
        "print(\"Best val_acc:\", study.best_value)\n",
        "print(\"Best params:\", study.best_params)\n",
        "\n",
        "# sobrescreve os seus hiperparâmetros para o treino final\n",
        "best = study.best_params\n",
        "learning_rate = best[\"lr\"]\n",
        "batch_size    = best[\"batch_size\"]\n",
        "dropout_rate  = best[\"dropout\"]\n",
        "weight_decay  = best[\"weight_decay\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "b3c563cb4d504091846f0fbde7690ab2",
            "73bb19b0ad5047e28a055f39507cbebd",
            "1c9938d9362846c7a8e1c32c32afe582",
            "99d4b4deff1b498cba1530738d421096",
            "801e59f4e06d493a9dcf1896ed255529",
            "ecab5f5170324b128808cd66f9251efc",
            "7cd594584b7845a9a22e763826ee83fa",
            "3a413f50f888414aa80afb6917b09c57",
            "6f7b5018078a438f89aa23f5dda5a21b",
            "4055d70b9e78405bbd3c0b31878d0927",
            "bb395ae3e1e64854a14a2eadc4055089"
          ]
        },
        "id": "BGfog2rw3UJV",
        "outputId": "c1e978d4-c551-442f-866c-c0315f72b9ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``group`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "[I 2025-09-28 21:18:31,943] A new study created in memory with name: no-name-0137954e-fd2b-4a9a-bfca-c9ada6f9d120\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/15 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3c563cb4d504091846f0fbde7690ab2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training loop\n",
        "\n",
        "# Build the model\n",
        "mlp = MLP(input_size=input_size, num_classes=num_classes,\n",
        "          activation_function=activation_function,\n",
        "          dropout_rate=dropout_rate).cuda()\n",
        "\n",
        "# Setting optimizer up\n",
        "optimizer = torch.optim.Adam(mlp.parameters(), lr=learning_rate,\n",
        "                             weight_decay=weight_decay)  # <<< usa weight_decay do Optuna\n",
        "\n",
        "# Early stopping setup\n",
        "best_loss = float('inf')\n",
        "patience = 5\n",
        "patience_counter = 0\n",
        "\n",
        "# Start training epochs loop\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "  epoch_loss = 0.0\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.view(-1,32*32*3).cuda() # flattenning images\n",
        "    labels = labels.cuda()\n",
        "\n",
        "    # Forward pass\n",
        "    optimizer.zero_grad()\n",
        "    outputs = mlp(images)\n",
        "\n",
        "    # Backward pass\n",
        "    loss = loss_function(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "\n",
        "    if (i+1) % 1000 == 0:\n",
        "      tqdm.write(f' Epoch {epoch + 1}/{num_epochs}, Step {i+1}/{len(train_dataset) // batch_size}, Loss: {loss}')\n",
        "\n",
        "  epoch_loss /= len(train_loader)\n",
        "  tqdm.write(f'Epoch {epoch+1} average loss: {epoch_loss:.4f}')\n",
        "\n",
        "  # Early stopping using loss value\n",
        "  if epoch_loss < best_loss:\n",
        "    best_loss = epoch_loss\n",
        "    patience_counter = 0\n",
        "  else:\n",
        "    patience_counter += 1\n",
        "    if patience_counter >= patience:\n",
        "      tqdm.write(\"Early stopping triggered.\")\n",
        "      break"
      ],
      "metadata": {
        "id": "XjTJpiboLmSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluate model (accuracy, precision, recall)\n",
        "mlp.eval()\n",
        "predictions = []\n",
        "labels = []\n",
        "for images, label in test_loader:\n",
        "  images = images.view(-1,32*32*3).cuda()\n",
        "  label = label.cuda()\n",
        "\n",
        "  output = mlp(images)\n",
        "  _, predicted = torch.max(output,1)\n",
        "\n",
        "  predictions.extend(predicted.cpu().numpy())\n",
        "  labels.extend(label.cpu().numpy())\n",
        "\n",
        "scores = get_scores(labels, predictions)\n",
        "print(\"Scores of your model\\n\", scores)"
      ],
      "metadata": {
        "id": "jMA-DgwPhkVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WWpu4Ka83-N6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QkgAfISZ4arr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# You can change/optimize this as you want\n",
        "- Different optimizers, activation functions, etc\n",
        "- Automatic hyperparameters optimization (Optuna)\n",
        "- Regularization techniques\n",
        "- Validation set to track metrics during epochs\n",
        "- Transform input data\n",
        "- ..."
      ],
      "metadata": {
        "id": "bA8HgFj-MjYc"
      }
    }
  ]
}